{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import log_softmax, softmax, logsumexp\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NCE: 0.4165\n",
      "Test calibrated NCE: 0.2400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class IterativeCalibration:\n",
    "\n",
    "    def __init__(self, num_classes, tolerance=1e-5):\n",
    "        self.num_classes = num_classes\n",
    "        self.tolerance = tolerance\n",
    "        self.alpha = 1\n",
    "        self.beta = np.zeros(num_classes)\n",
    "\n",
    "    def fit(self, alpha_train_logprobs, alpha_train_labels, beta_train_logprobs, beta_train_labels):\n",
    "        last_loss = float('inf')\n",
    "        for i in range(100):\n",
    "            new_alpha = self._next_alpha(alpha_train_logprobs, alpha_train_labels, self.alpha, self.beta)\n",
    "            new_beta = self._next_beta(beta_train_logprobs, beta_train_labels, new_alpha, self.beta)\n",
    "            loss = np.abs(new_alpha - self.alpha) + np.linalg.norm(new_beta - self.beta)\n",
    "            self.alpha = new_alpha\n",
    "            self.beta = new_beta\n",
    "            if np.abs(last_loss - loss) < self.tolerance:\n",
    "                break\n",
    "            last_loss = loss\n",
    "    \n",
    "    def _next_alpha(self, logprobs, labels, alpha, beta):\n",
    "        \n",
    "        def compute_alpha_loss(a):\n",
    "            ce = -np.mean(logprobs[np.arange(len(logprobs)), labels])\n",
    "            calprobs = softmax(a * logprobs + beta, axis=1)\n",
    "            soft_ce = -np.mean(np.sum(calprobs * logprobs, axis=1))\n",
    "            return np.abs(soft_ce - ce)\n",
    "\n",
    "        res = minimize(compute_alpha_loss, alpha, method='L-BFGS-B', tol=self.tolerance)\n",
    "        return res.x\n",
    "\n",
    "    def _next_beta(self, logprobs, labels, alpha, beta):\n",
    "        logpriors = np.log(np.bincount(labels) / len(labels))\n",
    "        logmean = np.log(np.mean(np.exp(alpha * logprobs) / np.sum(np.exp(alpha * logprobs + beta), axis=1, keepdims=True), axis=0))\n",
    "        return logpriors - logmean\n",
    "    \n",
    "    def calibrate(self, logprobs):\n",
    "        return log_softmax(self.alpha * logprobs + self.beta, axis=1)\n",
    "\n",
    "# dataset = \"sst2\"\n",
    "# size = 128\n",
    "# test_list = \"test_400\"\n",
    "dataset = \"banking77\"\n",
    "size = 616\n",
    "test_list = \"test_1000\"\n",
    "seed = 2\n",
    "train_logits = pd.read_csv(f\"../outputs/adaptation/llama3.2-1b/lora_ans_instruct/{dataset}_{size}_0.3_{seed}/test={dataset}/list=train_{size}_0.0_{seed}/logits.csv\", index_col=0, header=None).values.astype(float)\n",
    "train_logprobs = log_softmax(train_logits, axis=1)\n",
    "train_labels = pd.read_csv(f\"../outputs/adaptation/llama3.2-1b/lora_ans_instruct/{dataset}_{size}_0.3_{seed}/test={dataset}/list=train_{size}_0.0_{seed}/labels.csv\", index_col=0, header=None).values.astype(int).flatten()\n",
    "val_logits = pd.read_csv(f\"../outputs/adaptation/llama3.2-1b/lora_ans_instruct/{dataset}_{size}_0.3_{seed}/test={dataset}/list=val_{size}_0.3_{seed}/logits.csv\", index_col=0, header=None).values.astype(float)\n",
    "val_logprobs = log_softmax(val_logits, axis=1)\n",
    "val_labels = pd.read_csv(f\"../outputs/adaptation/llama3.2-1b/lora_ans_instruct/{dataset}_{size}_0.3_{seed}/test={dataset}/list=val_{size}_0.3_{seed}/labels.csv\", index_col=0, header=None).values.astype(int).flatten()\n",
    "test_logits = pd.read_csv(f\"../outputs/adaptation/llama3.2-1b/lora_ans_instruct/{dataset}_{size}_0.3_{seed}/test={dataset}/list={test_list}/logits.csv\", index_col=0, header=None).values.astype(float)\n",
    "test_logprobs = log_softmax(test_logits, axis=1)\n",
    "test_labels = pd.read_csv(f\"../outputs/adaptation/llama3.2-1b/lora_ans_instruct/{dataset}_{size}_0.3_{seed}/test={dataset}/list={test_list}/labels.csv\", index_col=0, header=None).values.astype(int).flatten()\n",
    "\n",
    "num_classes = train_logits.shape[1]\n",
    "calibrator = IterativeCalibration(num_classes, tolerance=1e-5)\n",
    "calibrator.fit(val_logprobs, val_labels, train_logprobs, train_labels)\n",
    "test_calibrated_logprobs = calibrator.calibrate(test_logits)\n",
    "\n",
    "test_ce = -np.mean(test_logprobs[np.arange(len(test_logprobs)), test_labels])\n",
    "test_ce_priors = -np.mean(np.log((np.bincount(test_labels) / len(test_labels))[test_labels]))\n",
    "print(f\"Test NCE: {test_ce/test_ce_priors:.4f}\")\n",
    "\n",
    "test_calibrated_ce = -np.mean(test_calibrated_logprobs[np.arange(len(test_calibrated_logprobs)), test_labels])\n",
    "test_calibrated_ce_priors = -np.mean(np.log((np.bincount(test_labels) / len(test_labels))[test_labels]))\n",
    "print(f\"Test calibrated NCE: {test_calibrated_ce/test_calibrated_ce_priors:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NCE: 0.3862\n"
     ]
    }
   ],
   "source": [
    "test_logits = pd.read_csv(f\"../outputs/adaptation/llama3.2-1b/lora_ans_instruct_all_train/{dataset}_{size}_0.0_{seed}/test={dataset}/list={test_list}/logits.csv\", index_col=0, header=None).values.astype(float)\n",
    "test_logprobs = log_softmax(test_logits, axis=1)\n",
    "test_labels = pd.read_csv(f\"../outputs/adaptation/llama3.2-1b/lora_ans_instruct_all_train/{dataset}_{size}_0.0_{seed}/test={dataset}/list={test_list}/labels.csv\", index_col=0, header=None).values.astype(int).flatten()\n",
    "\n",
    "test_ce = -np.mean(test_logprobs[np.arange(len(test_logprobs)), test_labels])\n",
    "test_ce_priors = -np.mean(np.log((np.bincount(test_labels) / len(test_labels))[test_labels]))\n",
    "print(f\"Test NCE: {test_ce/test_ce_priors:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
